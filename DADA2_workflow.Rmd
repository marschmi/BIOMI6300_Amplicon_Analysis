---
title: "DADA2 Workflow"
author: "Marian Schmidt"
date: "2023-03-07"
output: html_document
editor_options: 
  chunk_output_type: console
---

# Loading packages 
```{r}
# Be in the right place 
setwd("/workdir/mls528/BIOMI6300_Amplicon_Analysis")

# Efficient loading of the packages 
pacman::p_load(dada2, tidyverse, patchwork, phyloseq, Biostrings, install = FALSE)

#library("devtools")
#devtools::install_github("benjjneb/dada2")
#packageVersion("dada2")

# Load in the functions file 
source("code/functions.R")
```

# Set the path to the seq files 
```{r}
# Set path to the gzipped files 
path <- "data/sequencing"
path

# What files do we have?
list.files(path)

# Setting a variable with all the sample names by scanning our "samples" file 
samples <- scan("data/samples.txt", what = "character")
```

## Load in Forward and Reverse reads and assess the quality
```{r}
# Create variable for the forward and the reverse reads

# 1. Forward read variable 
forward_reads <- sort(list.files(path, pattern = "_L001_R1_001.fastq.gz", 
                      full.names = TRUE))
forward_reads

# 2. Reverse read variable 
reverse_reads <- sort(list.files(path, pattern = "_L001_R2_001.fastq.gz", 
                      full.names = TRUE))
reverse_reads

# 3. Place filtered files into filtered/subdirectory
# Create a variable holding file names for the Forward and Reverse filtered reads 

filtered_forward_reads <- file.path(path, "filtered", paste0(samples, "_R1_filtered.fastq.gz"))
filtered_reverse_reads <- file.path(path, "filtered", paste0(samples, "_R2_filtered.fastq.gz"))

# Show the quality of each base on the reads of first 4 samples 
forwardQual4_plot <- plotQualityProfile(forward_reads[1:4])
reverseQual4_plot <- plotQualityProfile(reverse_reads[1:4])

# Plot F and R together
forwardQual4_plot + reverseQual4_plot
```


# Filter & Trim Reads! 
We will use the `filterAndTrim` function, which:  

- `maxEE`: Quality filtering threshold being applied due to the expected errors. Here, sequences will be thrown away if it is likely to have more than 1 erroneous base call (we are specifying for both the forward and reverse reads separately).  
- `rm.phix`: removes any reads that match the PhiX bacteriophage genome, which is typically added to Illumina sequencing runs for quality monitoring.  
- `truncQ`: Set to 2 unless we specify otherwise, meaning it trims all bases after the first quality score of 2 it comes across in a read. 
- `maxN`: Set to 0 by default and will remove any sequences containing any Ns.
- `truncLen`: parameter will set the minimum size to trim the forward and reverse reads to in order to keep the quality scores roughly above 30 overall. Here we are using a program called figaro that assigned these values.  
- `trimLeft`: The number of nucleotides to remove from the start of each read. If both truncLen and trimLeft are provided, filtered reads will have length truncLen-trimLeft.

```{r filter-trim}
filtered_out <- filterAndTrim(forward_reads, filtered_forward_reads,
                              reverse_reads, filtered_reverse_reads,
                              truncLen = c(163,147), trimLeft = c(19,20),
                              maxN = 0, maxEE = c(1,1), truncQ = 2, 
                              rm.phix = TRUE, compress = TRUE, 
                              multithread = TRUE)
# 163-forward, 147-reverse

# Plot the quality of trimmed reads! 
forward_filteredQual4_plot <- plotQualityProfile(filtered_forward_reads[1:4])
reverse_filteredQual4_plot <- plotQualityProfile(filtered_reverse_reads[1:4])


# Put the plots all together into one gigantic plot :) 
(forwardQual4_plot + reverseQual4_plot) / (forward_filteredQual4_plot + reverse_filteredQual4_plot) 
```


# Generate an error model 
```{r learn-errors}
# Learn errors
err_forward_reads <- learnErrors(filtered_forward_reads, multithread = TRUE)
err_reverse_reads <- learnErrors(filtered_reverse_reads, multithread = TRUE)

# Plot the errors
plotErrors(err_forward_reads, nominalQ = TRUE)
plotErrors(err_reverse_reads, nominalQ = TRUE)
```


# Inferring ASVs on the forward and reverse sequences 
```{r infer-ASVs}
# run dada2 on the forward seqs
dada_forward <- dada(filtered_forward_reads, err = err_forward_reads, multithread = TRUE)
type(dada_forward)
dada_forward$`20211005-MA-SCS2F_S63_R1_filtered.fastq.gz`

# run dada2 on the reverse sequences 
dada_reverse <- dada(filtered_reverse_reads, err = err_reverse_reads, multithread = TRUE)
dada_reverse[1]
dada_reverse[30]
```


# Merge forward and reverse ASVs 
```{r merge-FandR-ASVs}
# Merge the forward ASVs and the reverse ASVs
merged_amplicons <- mergePairs(dada_forward, filtered_forward_reads, 
                               dada_reverse, filtered_reverse_reads,
                               verbose = TRUE)
# Evaluate the output 
typeof(merged_amplicons)
merged_amplicons
length(merged_amplicons)
names(merged_amplicons)

merged_amplicons[1]
merged_amplicons[30]
```


# Generate a count table! 
```{r gen-countTable-seqTab}
seqtab <- makeSequenceTable(merged_amplicons)
class(seqtab)
typeof(seqtab)
dim(seqtab)
View(seqtab)

# Inspect the distribution of sequence lengths of all ASVs in dataset 
table(nchar(getSequences(seqtab)))
```

I have `r ncol(seqtab)` ASVs in the dataset! 

# Check & Remove for Chimeras (Bimeras)

```{r check-chimeras}
# Identify and remove chimeras 
seqtab_nochim <- removeBimeraDenovo(seqtab, verbose = TRUE)
# 603 chimeras removed! 

# What proportion of counts were removed? 
chim_check <- sum(seqtab_nochim)/sum(seqtab) # 0.9725445
frac_removed <- (1-chim_check)*100
frac_removed
```

Chimeras represented `r frac_removed` percent of the data. 

# Track the sequences through the pipeline 

```{r track-seqs}
# create a little function to identify number seqs 
getN <- function(x) sum(getUniques(x))

# Make the table to track the seqs 
track <- cbind(filtered_out, 
               sapply(dada_forward, getN),
               sapply(dada_reverse, getN),
               sapply(merged_amplicons, getN),
               rowSums(seqtab_nochim))

head(track)

# Change column names 
colnames(track) <- c("input", "filtered", "denoisedF", "denoisedR", "merged", "nochim")
rownames(track) <- samples

# Generate a plot to track the reads through our DADA2 pipeline
track %>%
  # make it a dataframe
  as.data.frame() %>%
  rownames_to_column(var = "names") %>%
  pivot_longer(input:nochim, names_to = "read_type", values_to = "num_reads") %>%
  make_MA_metadata() %>%
  mutate(read_type = fct_relevel(read_type, 
                                 "input", "filtered", "denoisedF", "denoisedR", "merged", "nochim")) %>%
  ggplot(aes(x = read_type, y = num_reads, fill = read_type)) + 
  facet_grid(~fraction) + 
  geom_line(aes(group = names), color = "grey") + 
  geom_point(shape = 21, size = 3, alpha = 0.8) + 
  scale_fill_brewer(palette = "Spectral") + 
  theme_bw() + 
  labs(x = "Filtering Step", y = "Number of Sequences") +
  theme(legend.position = "bottom", legend.title = element_blank(),
        axis.text.x = element_text(angle = 45, vjust = 1, hjust = 1))


# First, let's source the colors_and_shapes.R
# This file is in /workdir/in_class_data/colors_and_shapes.R
source("code/colors_and_shapes.R")


# Plot the percent reads retained 
track %>%
  as.data.frame() %>%
  mutate(percent_reads_retained = round((nochim/input)*100, digits = 2)) %>%
  rownames_to_column(var = "names") %>% # As input to make_MA_metadata
  make_MA_metadata() %>%
  # Make the plot! 
  ggplot(aes(x = fraction, y = percent_reads_retained, fill = fraction)) + 
  geom_jitter(shape = 21, size = 3, alpha = 0.8) + 
  geom_boxplot(alpha = 0.4, outlier.shape = NA) + 
  scale_fill_manual(values = fraction_colors) + 
  theme_bw() + 
  labs(y = "Percent Sequences Retained by DADA2") +
  theme(axis.title.x = element_blank())
```


# Assign Taxonomy 

Here, we will use the silva database version 138!
```{r assign-tax}
# The next line took 2 mins to run
taxa <- assignTaxonomy(seqtab_nochim, "/workdir/in_class_data/taxonomy/silva_nr99_v138.1_train_set.fa.gz", multithread=TRUE)

# the next line took 3 minutes 
taxa <- addSpecies(taxa, "/workdir/in_class_data/taxonomy/silva_species_assignment_v138.1.fa.gz")

# Inspect the taxonomy 
taxa_print <- taxa # Removing sequence rownames for display only
rownames(taxa_print) <- NULL
View(taxa_print)
```


# Evaluate Accuracy 

```{r eval-accuracy}
# Check the mock commmunity 
mock_sample <- seqtab_nochim["MockZymoPos_S84_R1_filtered.fastq.gz",]
length(mock_sample)

# Drop ASVs absent from mock community 
length(mock_sample[mock_sample > 0])

mock_sample_sub <- sort(mock_sample[mock_sample > 0], decreasing = TRUE)
length(mock_sample_sub)

cat("DADA2 inferred", length(mock_sample_sub), "ASVs present in the Mock Community.")

#Who are they in the mock community? 
View(taxa[row.names(taxa) %in% names(mock_sample_sub), ])

#### Compare our ASVs from the mock community to the reference fasta!
mock_reference <- getSequences(file.path("/workdir/in_class_data/", "mock_community.fasta"))

match_mock_ref <- sum(sapply(names(mock_sample_sub),
                             function(x) any(grepl(x, mock_reference))))

cat(sum(match_mock_ref), "ASVs were exact mactches to the expected reference sequences.")
```


# Prepare the data for export! 
## 1. ASV Table 

```{r prepare-ASV-table}
# Prep the asv table! 
samples_out <- rownames(seqtab_nochim)

# Pull out sample names from the fastq file name 
sample_names_reformatted <- sapply(strsplit(samples_out, split = "_"), `[`, 1)

# Replace the names in our seqtable 
rownames(seqtab_nochim) <- sample_names_reformatted

### intuition check 
stopifnot(rownames(seqtab_nochim) == sample_names_reformatted)

############## Modify the ASV names and then save a fasta file! 
# Give headers more manageable names
# First pull the ASV sequences
asv_seqs <- colnames(seqtab_nochim)

# make headers for our ASV seq fasta file, which will be our asv names
asv_headers <- vector(dim(seqtab_nochim)[2], mode = "character")

# loop through vector and fill it in with ASV names 

for (i in 1:dim(seqtab_nochim)[2]) {
  asv_headers[i] <- paste(">ASV", i, sep = "_")
}

# intitution check
asv_headers


##### Rename ASVs in table then write out our ASV fasta file! 
View(seqtab_nochim)
asv_tab <- t(seqtab_nochim)
View(asv_tab)

## Rename our asvs! 
row.names(asv_tab) <- sub(">", "", asv_headers)
View(asv_tab)

# Write the count table to a file! 
write.table(asv_tab, "data/ASV_counts.tsv", sep = "\t", quote = FALSE, col.names = NA)

# Write out the fasta file for reference later on for what seq matches what ASV
asv_fasta <- c(rbind(asv_headers, asv_seqs))
# Save to a file!
write(asv_fasta, "data/ASVs.fasta")
```

## 2. Taxonomy Table 
```{r prepare-tax-table}
View(taxa)

##### Prepare tax table 
# Add the ASV sequences from the rownames to a column 
new_tax_tab <- taxa %>%
  as.data.frame() %>%
  rownames_to_column(var = "ASVseqs") 
head(new_tax_tab)

# intution check 
stopifnot(new_tax_tab$ASVseqs == colnames(seqtab_nochim))

# Now let's add the ASV names 
rownames(new_tax_tab) <- rownames(asv_tab)
View(new_tax_tab)

### Final prep of tax table. Add new column with ASV names 
asv_tax <- 
  new_tax_tab %>%
  # add rownames from count table for phyloseq handoff
  mutate(ASV = rownames(asv_tab)) %>%
  # Resort the columns with select
  dplyr::select(Kingdom, Phylum, Class, Order, Family, Genus, Species, ASV, ASVseqs)

View(asv_tax)

# Intution check
stopifnot(asv_tax$ASV == rownames(asv_tax), rownames(asv_tax) == rownames(asv_tab))

# Write the table 
write.table(asv_tax, "data/ASV_taxonomy.tsv", sep = "\t", quote = FALSE, col.names = NA)
```


## 3. Metadata 

```{r metadata-prep}
# Read in metadata 
metadata <- 
  read.csv("data/metadata.csv") %>%
  mutate(X = NULL) %>%
  # fix typo 
  mutate(Sample_or_Control = droplevels(fct_recode(Sample_or_Control, "True Sample" = " True Sample")))

str(metadata)

# Add names to rownames for phyloseq happiness 
rownames(metadata) <- metadata$names
```

Time to give our data to phyloseq! 

## Handoff to phyloseq 
```{r phyloseq-handoff}
raw_physeq <- phyloseq(otu_table(asv_tab, taxa_are_rows = TRUE),
                         sample_data(metadata),
                         tax_table(as.matrix(asv_tax)))
raw_physeq

save(raw_physeq, file = paste0("data/raw_physeq.RData"))
```







